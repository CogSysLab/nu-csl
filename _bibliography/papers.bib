---
---

@string{aps = {American Physical Society,}}



@article{potter2024multistatic,
  title={Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A Bayesian Fusion Approach},
  author={Potter, Michael and Akcakaya, Murat and Necsoiu, Marius and Schirner, Gunar and Erdo{\u{g}}mus, Deniz and Imbiriba, Tales},
  renamed={Deniz Erdogmus},
  journal={IEEE Transactions on Aerospace and Electronic Systems},
  year={2024},
  publisher={IEEE},
  preview={J_Potter_UAVRec_TAES_2024.png},
  abstract={Radar Automated Target Recognition (RATR) for Unmanned Aerial Vehicles (UAVs) involves transmitting Electromagnetic Waves (EMWs) and performing target type recognition on the received radar echo, which has important applications in defense and aerospace. Previous work has demonstrated the benefits of employing multistatic radar configurations in RATR compared to monostatic radar configurations. However, multistatic radar configurations commonly use fusion methods which combine the classification vectors of multiple individual radars suboptimally from a probabilistic perspective.
     To address this issue, this work leverages Bayesian analysis to provide a fully Bayesian RATR framework for UAV type classification. Specifically, we employ an Optimal Bayesian Fusion (OBF) method, from the Bayesian perspective of expected 0-1 loss, to formulate a posterior distribution that aggregates the classification probability vectors from multiple individual radar observations at a given time step. This OBF method is used to update a separate Recursive Bayesian Classification (RBC) posterior distribution on the target UAV type. The RBC posterior is conditioned on all historical observations made from multiple radars across multiple time steps.
    To evaluate the proposed approach, we simulate random walk trajectories for seven drones and correspond the target’s aspect angles to Radar Cross Section (RCS) measurements acquired in an anechoic chamber. We then compare the performance of single radar Automated Target Recognition (ATR) system and suboptimal fusion methods against the OBF method. We empirically show that the OBF method, integrated with RBC, significantly outperforms other fusion methods and single radar configuration in terms of classification accuracy.
    },
  html={https://ieeexplore.ieee.org/abstract/document/10638802},
    dimensions={true},
    status={published},
    selected={true},
    abbr={TAES},
}

@misc{potter2024continuouslyoptimizingradarplacement,
      title={Continuously Optimizing Radar Placement with Model Predictive Path Integrals},
      author={Michael Potter and Shuo Tang and Paul Ghanem and Milica Stojanovic and Pau Closas and Murat Akcakaya and Ben Wright and Marius Necsoiu and Deniz Erdogmus and Michael Everett and Tales Imbiriba},
      renamed={Deniz Erdogmus},
      year={2024},
      journal={IEEE Transactions on Aerospace and Electronic Systems},
      eprint={2405.18999},
      archivePrefix={arXiv},
      primaryClass={stat.AP},
      url={https://arxiv.org/abs/2405.18999},
      abstract={Continuously optimizing sensor placement is essential for precise target localization in various military and civilian applications. While information theory has shown promise in optimizing sensor placement, many studies oversimplify sensor measurement models or neglect dynamic constraints of mobile sensors. To address these challenges, we employ a range measurement model that incorporates radar parameters and radar-target distance, coupled with Model Predictive Path Integral (MPPI) control to manage complex environmental obstacles and dynamic constraints. We compare the proposed approach against stationary radars or simplified range measurement models based on the root mean squared error (RMSE) of the Cubature Kalman Filter (CKF) estimator for the targets' state. Additionally, we visualize the evolving geometry of radars and targets over time, highlighting areas of highest measurement information gain, demonstrating the strengths of the approach. The proposed strategy outperforms stationary radars and simplified range measurement models in target localization, achieving a 38-74% reduction in mean RMSE and a 33-79% reduction in the upper tail of the 90% Highest Density Interval (HDI) over 500 Monte Carl (MC) trials across all time steps.
Code will be made publicly available upon acceptance.},
    preview={J_Potter_MPPI_TAES_2024.jpg},
      dimensions={true},
      status={published},
      html={https://arxiv.org/abs/2405.18999},
      abbr={TAES},
}

@article{potter2024robust,
  title={Robust Survival Analysis with Adversarial Regularization},
  author={Potter, Michael and Maxenti, Stefano and Everett, Michael},
  renamed={Deniz Erdogmus},
  journal={arXiv preprint arXiv:2312.16019},
  year={2024},
  abstract={Survival Analysis (SA) models the time until an event occurs, with applications in fields like medicine, defense, finance, and aerospace. Recent research indicates that Neural Networks (NNs) can effectively capture complex data patterns in SA, whereas simple generalized linear models often fall short in this regard. However, dataset uncertainties (e.g., noisy measurements, human error) can degrade NN model performance. To address this, we leverage advances in NN verification to develop training objectives for robust, fully-parametric SA models. Specifically, we propose an adversarially robust loss function based on a Min-Max optimization problem. We employ CROWN-Interval Bound Propagation (CROWN-IBP) to tackle the computational challenges inherent in solving this Min-Max problem. Evaluated over 10 SurvSet datasets, our method, Survival Analysis with Adversarial Regularization (SAWAR), consistently outperforms baseline adversarial training methods and state-of-the-art (SOTA) deep SA models across various covariate perturbations with respect to Negative Log Likelihood (NegLL), Integrated Brier Score (IBS), and Concordance Index (CI) metrics. Thus, we demonstrate that adversarial robustness enhances SA predictive performance and calibration, mitigating data uncertainty and improving generalization across diverse datasets by up to 150% compared to baselines.},
  preview={J_Potter_SAWAR_ICHI_2024.png},
  url={https://arxiv.org/abs/2312.16019},
  html=https://arxiv.org/abs/2312.16019,
  status={published},
  abbr={ICHI},
}

@article{sunger2023tubular,
  title={Tubular Curvature Filter: Implicit Pointwise Curvature Calculation Method for Tubular Objects},
  author={Sunger, Elifnur and Kalkanli, Beyza and Yildiz, Veysi and Imbiriba, Tales and Campbell, Peter and Erdogmus, Deniz},
  renamed={Deniz Erdogmus},
  journal={arXiv preprint arXiv:2311.11931},
  abstract={Curvature estimation methods are important as they capture salient features for various applications in image processing, especially within medical domains where tortuosity of vascular structures is of significant interest. Existing methods based on centerline or skeleton curvature fail to capture curvature gradients across a rotating tubular structure. This paper presents a Tubular Curvature Filter method that locally calculates the acceleration of bundles of curves that traverse along the tubular object parallel to the centerline. This is achieved by examining the directional rate of change in the eigenvectors of the Hessian matrix of a tubular intensity function in space. This method implicitly calculates the local tubular curvature without the need to explicitly segment the tubular object. Experimental results demonstrate that the Tubular Curvature Filter method provides accurate estimates of local curvature at any point inside tubular structures.},
  preview={J_Sunger&Kalkanli_CurvatureFilter_TIP.png},
  html=https://arxiv.org/abs/2311.11931,
  year={2023},
  status={under review},
  abbr={TIP},
}

@article{akbar2024advancing,
  title={Advancing post-traumatic seizure classification and biomarker identification: Information decomposition based multimodal fusion and explainable machine learning with missing neuroimaging data},
  author={Akbar, Md Navid and Ruf, Sebastian F and Singh, Ashutosh and Faghihpirayesh, Razieh and Garner, Rachael and Bennett, Alexis and Alba, Celina and La Rocca, Marianna and Imbiriba, Tales and Erdo{\u{g}}mu{\c{s}}, Deniz and others},
 renamed={Ashutosh Singh , Tales Imbiriba, Deniz Erdogmus},
  journal={Computerized Medical Imaging and Graphics},
  volume={115},
  pages={102386},
  year={2024},
  publisher={Elsevier},
  status={published},
  html={https://www.sciencedirect.com/science/article/pii/S0895611124000636},
  abstract={A late post-traumatic seizure (LPTS), a consequence of traumatic brain injury (TBI), can potentially evolve into a lifelong condition known as post-traumatic epilepsy (PTE). Presently, the mechanism that triggers epileptogenesis in TBI patients remains elusive, inspiring the epilepsy community to devise ways to predict which TBI patients will develop PTE and to identify potential biomarkers. In response to this need, our study collected comprehensive, longitudinal multimodal data from 48 TBI patients across multiple participating institutions. A supervised binary classification task was created, contrasting data from LPTS patients with those without LPTS. To accommodate missing modalities in some subjects, we took a two-pronged approach. Firstly, we extended a graphical model-based Bayesian estimator to directly classify subjects with incomplete modality. Secondly, we explored conventional imputation techniques. The imputed multimodal information was then combined, following several fusion and dimensionality reduction techniques found in the literature, and subsequently fitted to a kernel- or a tree-based classifier. For this fusion, we proposed two new algorithms: recursive elimination of correlated components (RECC) that filters information based on the correlation between the already selected features, and information decomposition and selective fusion (IDSF), which effectively recombines information from decomposed multimodal features. Our cross-validation findings showed that the proposed IDSF algorithm delivers superior performance based on the area under the curve (AUC) score. Ultimately, after rigorous statistical comparisons and interpretable machine learning examination using Shapley values of the most frequently selected features, we recommend the two following magnetic resonance imaging (MRI) abnormalities as potential biomarkers: the left anterior limb of internal capsule in diffusion MRI (dMRI), and the right middle temporal gyrus in functional MRI (fMRI).},
  preview={J_Akbar_LPTS_CMIG_2024.png},
  abbr={CMIG},
}

@article{singh2024learning,
  title={Learning Semilinear Neural Operators: A Unified Recursive Framework For Prediction And Data Assimilation},
  author={Singh, Ashutosh and Borsoi, Ricardo Augusto and Erdogmus, Deniz and Imbiriba, Tales},
 renamed={Ashutosh Singh, Tales Imbiriba, Deniz Erdogmus},
  journal={International Conference on Learning Representations},
  year={2024},
    status={published},
    pdf={https://openreview.net/pdf?id=ZMv6zKYYUs},
    selected={true},
    preview={C_Singh_LNO_ICLR_2024.webp},
    abstract={Recent advances in the theory of Neural Operators (NOs) have enabled fast and
accurate computation of the solutions to complex systems described by partial
differential equations (PDEs). Despite their great success, current NO-based solutions face important challenges when dealing with spatio-temporal PDEs over
long time scales. Specifically, the current theory of NOs does not present a systematic framework to perform data assimilation and efficiently correct the evolution of PDE solutions over time based on sparsely sampled noisy measurements.
In this paper, we propose a learning-based state-space approach to compute the
solution operators to infinite-dimensional semilinear PDEs. Exploiting the structure of semilinear PDEs and the theory of nonlinear observers in function spaces,
we develop a flexible recursive method that allows for both prediction and data
assimilation by combining prediction and correction operations. The proposed
framework is capable of producing fast and accurate predictions over long time
horizons, dealing with irregularly sampled noisy measurements to correct the solution, and benefits from the decoupling between the spatial and temporal dynamics of this class of PDEs. We show through experiments on the KuramotoSivashinsky, Navier-Stokes and Korteweg-de Vries equations that the proposed
model is robust to noise and can leverage arbitrary amounts of measurements to
correct its prediction over a long time horizon with little computational overhead.},
abbr={ICLR},
    }

@article{mcveigh2024variational,
  title={A Variational Autoencoder-Based Method to Investigate Degeneracy in the Neural Correlates of Psychological Concepts},
  author={Kieran McVeigh and Ashutosh Singh and Deniz Erdogmus and Lisa Feldman Barrett and Ajay B. Satpute},
  renamed={Ashutosh Singh , Deniz Erdogmus},
  journal={Social & Affective Neuroscience Society},
  year={2024},
  status={published},
  pdf={https://socialaffectiveneuro.org/wp-content/uploads/2024/05/SANS-Conference-2024_Program_Final.pdf},
  preview={C_McVeigh_VAE_SANS_2024.png},
  abbr={SANS},
}

@article{imbiriba2023wearable,
  title={Wearable biosensing to predict imminent aggressive behavior in psychiatric inpatient youths with autism},
  author={Imbiriba, Tales and Demirkaya, Ahmet and Singh, Ashutosh and Erdogmus, Deniz and Goodwin, Matthew S},
  renamed={Ashutosh Singh , Tales Imbiriba, Deniz Erdogmus},
  journal={JAMA network open},
  volume={6},
  number={12},
  pages={e2348898--e2348898},
  year={2023},
  publisher={American Medical Association},
  abstract={IMPORTANCE Aggressive behavior is a prevalent and challenging issue in individuals with autism.
OBJECTIVE To investigate whether changes in peripheral physiology recorded by a wearable
biosensor and machine learning can be used to predict imminent aggressive behavior before it occurs
in inpatient youths with autism.
DESIGN, SETTING, AND PARTICIPANTS This noninterventional prognostic study used data
collected from March 2019 to March 2020 from 4 primary care psychiatric inpatient hospitals.
Enrolled participants were 86 psychiatric inpatients with confirmed diagnoses of autism exhibiting
operationally defined self-injurious behavior, emotion dysregulation, or aggression toward others; 16
individuals were not included (18.6%) because they would not wear the biosensor (8 individuals) or
were discharged before an observation could be made (8 individuals). Data were analyzed from
March 2020 through October 2023.
MAIN OUTCOMES AND MEASURES Research staff performed live behavioral coding of aggressive
behavior while inpatient study participants wore a commercially available biosensor that recorded
peripheral physiological signals (cardiovascular activity, electrodermal activity, and motion). Logistic
regression, support vector machines, neural networks, and domain adaptation were used to analyze
time-series features extracted from biosensor data. Area under the receiver operating characteristic
curve (AUROC) values were used to evaluate the performance of population- and persondependent models.},
    status={published},
    html={https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2813185},
    preview={J_Imbiriba_Aggression_JAMA_2023.webp},
    status={published},
    abbr={JAMA},
}

@inproceedings{singh2023inv,
  title={Inv-senet: Invariant self expression network for clustering under biased data},
  author={Singh, Ashutosh and Singh, Ashish and Masoomi, Aria and Imbiriba, Tales and Learned-Miller, Erik and Erdo{\u{g}}mu{\c{s}}, Deniz},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  renamed={Ashutosh Singh , Tales Imbiriba, Deniz Erdogmus},
  year={2023},
  organization={IEEE},
  status={published},
  html={https://ieeexplore.ieee.org/abstract/document/10094998?casa_token=WdpTY4H9IlkAAAAA:fA3xRe9xHvtaqk4FM7Z4k27gxmWWvuTfHBv6AB6iqAuIjzxRB10DZyJPa-7n7ITSuoTgMb7VXvg},
    preview={C_Singh_InvSenet_ICASSP_2023.png},
    abstract={Subspace clustering algorithms are used for understanding the cluster structure that explains the patterns prevalent in the dataset well. These methods are extensively used for data-exploration tasks in various areas of Natural Sciences. However, most of these methods fail to handle confounding attributes in the dataset. For datasets where a data sample represent multiple attributes, naively applying any clustering approach can result in undesired output. To this end, we propose a novel framework for jointly removing confounding attributes while learning to cluster data points in individual subspaces. Assuming we have label information about these confounding attributes, we regularize the clustering method by adversarially learning to minimize the mutual information between the data representation and the confounding attribute labels. Our experimental result on synthetic and real-world datasets demonstrate the effectiveness of our approach.},
abbr={ICASSP},
}

@inproceedings{singh2021corr,
    title={Variation in brain correlates of emotional experience},
    author={Christiana Westlin* and Ashutosh Singh* and Dana H Brooks and Deniz Erdogmus and Lisa Feldman Barrett},
    renamed={Ashutosh Singh , Deniz Erdogmus},
    year={2022},
    booktitle={Society for Affective Science Annual Conference},
    status={published},
    abstract={For the last several decades, emotion research has attempted to identify a "biomarker" or consistent pattern of brain activity to characterize a single category of emotion (e.g., fear) that will remain consistent across all instances of that category, regardless of individual and context. In this study, we investigated variation rather than consistency during emotional experiences while people watched video clips chosen to evoke instances of specific emotion categories. Specifically, we developed a sequential probabilistic approach to model the temporal dynamics in a participant’s brain activity during video viewing. We characterized brain states during these clips as distinct state occupancy periods between state transitions in blood oxygen level dependent (BOLD) signal patterns. We found substantial variation in the state occupancy probability distributions across individuals watching the same video, supporting the hypothesis that when it comes to the brain correlates of emotional experience, variation may indeed be the norm.},
    preview={C_Singh_VAE_SAS_2022.webp},
    pdf={https://society-for-affective-science.org/wp-content/uploads/2023/09/2022-SAS-Program-v9.pdf},
abbr={SAS},
}

@inproceedings{singh2021variation,
  title={Variation is the norm: Brain state dynamics evoked by emotional video clips},
  author={Singh, Ashutosh and Westlin, Christiana and Eisenbarth, Hedwig and Losin, Elizabeth A Reynolds and Andrews-Hanna, Jessica R and Wager, Tor D and Satpute, Ajay B and Barrett, Lisa Feldman and Brooks, Dana H and Erdogmus, Deniz},
  renamed={Ashutosh Singh , Deniz Erdogmus},
  booktitle={2021 43rd Annual International Conference of the IEEE Engineering in Medicine \& Biology Society (EMBC)},
  pages={6003--6007},
  year={2021},
  organization={IEEE},
  status={published},
  preview={C_Singh_VAE_EMBC_2021.png},
  abstract={For the last several decades, emotion research has
attempted to identify a “biomarker” or consistent pattern of
brain activity to characterize a single category of emotion
(e.g., fear) that will remain consistent across all instances of
that category, regardless of individual and context. In this
study, we investigated variation rather than consistency during
emotional experiences while people watched video clips chosen
to evoke instances of specific emotion categories. Specifically,
we developed a sequential probabilistic approach to model the
temporal dynamics in a participant’s brain activity during video
viewing. We characterized brain states during these clips as
distinct state occupancy periods between state transitions in
blood oxygen level dependent (BOLD) signal patterns. We found
substantial variation in the state occupancy probability distributions across individuals watching the same video, supporting
the hypothesis that when it comes to the brain correlates of
emotional experience, variation may indeed be the norm.},
abbr={EMBC},
}

@article{gonzalez2022feedback,
  title={Feedback related potentials for EEG-based typing systems},
  author={Gonzalez-Navarro, Paula and Celik, Basak and Moghadamfalahi, Mohammad and Akcakaya, Murat and Fried-Oken, Melanie and Erdo{\u{g}}mu{\c{s}}, Deniz},
  journal={Frontiers in Human Neuroscience},
  volume={15},
  pages={788258},
  year={2022},
  publisher={Frontiers Media SA},
  renamed={Basak Celik , Deniz Erdogmus},
  status={published},
  abstract={Error related potentials (ErrP), which are elicited in the EEG in response to a perceived error, have been used for error correction and adaption in the event related potential (ERP)-based brain computer interfaces designed for typing. In these typing interfaces, ERP evidence is collected in response to a sequence of stimuli presented usually in the visual form and the intended user stimulus is probabilistically inferred (stimulus with highest probability) and presented to the user as the decision. If the inferred stimulus is incorrect, ErrP is expected to be elicited in the EEG. Early approaches to use ErrP in the design of typing interfaces attempt to make hard decisions on the perceived error such that the perceived error is corrected and either the sequence of stimuli are repeated to obtain further ERP evidence, or without further repetition the stimulus with the second highest probability is presented to the user as the decision of the system. Moreover, none of the existing approaches use a language model to increase the performance of typing. In this work, unlike the existing approaches, we study the potential benefits of fusing feedback related potentials (FRP), a form of ErrP, with ERP and context information (language model, LM) in a Bayesian fashion to detect the user intent. We present experimental results based on data from 12 healthy participants using RSVP Keyboard™ to complete a copy-phrase-task. Three paradigms are compared: [P1] uses only ERP/LM Bayesian fusion; [P2] each RSVP sequence is appended with the top candidate in the alphabet according to posterior after ERP evidence fusion; corresponding FRP is then incorporated; and [P3] the top candidate is shown as a prospect to generate FRP evidence only if its posterior exceeds a threshold. Analyses indicate that ERP/LM/FRP evidence fusion during decision making yields significant speed-accuracy benefits for the user.},
  html={https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2021.788258/full},
  abbr={FHN},
  preview={J_Gonzalez_feedback_FHN_2022.webp},
}

@article{klee2022target,
  title={Target-related alpha attenuation in a brain-computer interface rapid serial visual presentation calibration},
  author={Klee, Daniel and Memmott, Tab and Smedemark-Margulies, Niklas and Celik, Basak and Erdogmus, Deniz and Oken, Barry S},
  journal={Frontiers in Human Neuroscience},
  volume={16},
  pages={882557},
  year={2022},
  publisher={Frontiers Media SA},
    renamed={Basak Celik , Deniz Erdogmus , Daniel Klee},
    status={published},
    abbrev={FHN},
    abstract={This study evaluated the feasibility of using occipitoparietal alpha activity to drive target/non-target classification in a brain-computer interface (BCI) for communication. EEG data were collected from 12 participants who completed BCI Rapid Serial Visual Presentation (RSVP) calibrations at two different presentation rates: 1 and 4 Hz. Attention-related changes in posterior alpha activity were compared to two event-related potentials (ERPs): N200 and P300. Machine learning approaches evaluated target/non-target classification accuracy using alpha activity. Results indicated significant alpha attenuation following target letters at both 1 and 4 Hz presentation rates, though this effect was significantly reduced in the 4 Hz condition. Target-related alpha attenuation was not correlated with coincident N200 or P300 target effects. Classification using posterior alpha activity was above chance and benefitted from individualized tuning procedures. These findings suggest that target-related posterior alpha attenuation is detectable in a BCI RSVP calibration and that this signal could be leveraged in machine learning algorithms used for RSVP or comparable attention-based BCI paradigms.},
    html={https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2022.882557/full},
    preview={J_Klee_target_FHN_2022.webp},
}

@article{bicer2024user,
  title={User Training With Error Augmentation for sEMG-Based Gesture Classification},
  author={Bicer, Yunus and Smedemark-Margulies, Niklas and Celik, Basak and Sunger, Elifnur and Orendorff, Ryan and Naufel, Stephanie and Imbiriba, Tales and Erdo{\u{g}}mu{\c{s}}, Deniz and Tunik, Eugene and Yarossi, Mathew},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  year={2024},
  publisher={IEEE},
    status={published},
    preview={J_Bicer_sEMG_TNSRE_2024.jpg},
    abstract={We designed and tested a system for real-time control of a user interface by extracting surface electromyographic (sEMG) activity from eight electrodes in a wristband configuration. sEMG data were streamed into a machine-learning algorithm that classified hand gestures in real-time. After an initial model calibration, participants were presented with one of three types of feedback during a human-learning stage: veridical feedback, in which predicted probabilities from the gesture classification algorithm were displayed without alteration; modified feedback, in which we applied a hidden augmentation of error to these probabilities; and no feedback. User performance was then evaluated in a series of minigames, in which subjects were required to use eight gestures to manipulate their game avatar to complete a task. Experimental results indicated that relative to the baseline, the modified feedback condition led to significantly improved accuracy. Class separation also improved, though this trend was not significant. These findings suggest that real-time feedback in a gamified user interface with manipulation of feedback may enable intuitive, rapid, and accurate task acquisition for sEMG-based gesture recognition applications.},
    abbr={TNSRE},
    html={https://pubmed.ncbi.nlm.nih.gov/38427549/},
    renamed={Basak Celik , Deniz Erdogmus , Yunus Bicer, Elifnur Sunger},
}
@inproceedings{smedemark2023recursive,
  title={Recursive Estimation of User Intent From Noninvasive Electroencephalography Using Discriminative Models},
  author={Smedemark-Margulies, Niklas and Celik, Basak and Imbiriba, Tales and Kocanaogullari, Aziz and Erdo{\u{g}}mu{\c{s}}, Deniz},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE},
    status={published},
    pdf={https://arxiv.org/pdf/2211.02630},
    abstract={We study the problem of inferring user intent from noninvasive electroencephalography (EEG) to restore communication for people with severe speech and physical impairments (SSPI). The focus of this work is improving the estimation of posterior symbol probabilities in a typing task. At each iteration of the typing procedure, a subset of symbols is chosen for the next query based on the current probability estimate. Evidence about the user's response is collected from event-related potentials (ERP) in order to update symbol probabilities, until one symbol exceeds a predefined confidence threshold. We provide a graphical model describing this task, and derive a recursive Bayesian update rule based on a discriminative probability over label vectors for each query, which we approximate using a neural network classifier. We evaluate the proposed method in a simulated typing task and show that it outperforms previous approaches based on generative modeling.},
    preview={C_Smedemark_recursive_ICASSP_2023.jpg},
    abbr={ICASSP},
    selected={true},
    renamed={Basak Celik , Deniz Erdogmus , Niklas Smedemark-Margulies},
}


@article{smedemarkfast,
  title={Fast and Expressive Gesture Recognition using a Combination-Homomorphic Electromyogram Encoder},
  author={Smedemark-Margulies, Niklas and Bicer, Yunus and Sunger, Elifnur and Imbiriba, Tales and Tunik, Eugene and Erdogmus, Deniz and Yarossi, Mathew and Walters, Robin},
  journal={Transactions on Machine Learning Research},
  renamed={Niklas Smedemark-Margulies, Yunus Bicer, Elifnur Sunger, Deniz Erdogmus},
  preview={J_Smedemark-Margulies_CombinationHomomorphicEMGEncoder_TMLR_2024.webp},
  abstract={We study the task of gesture recognition from electromyography (EMG), with the goal of
enabling expressive human-computer interaction at high accuracy, while minimizing the
time required for new subjects to provide calibration data. To fulfill these goals, we define
combination gestures consisting of a direction component and a modifier component. New
subjects only demonstrate the single component gestures and we seek to extrapolate from
these to all possible single or combination gestures. We extrapolate to unseen combination
gestures by combining the feature vectors of real single gestures to produce synthetic training
data. This strategy allows us to provide a large and flexible gesture vocabulary, while not
requiring new subjects to demonstrate combinatorially many example gestures. We pre-train
an encoder and a combination operator using self-supervision, so that we can produce useful
synthetic training data for unseen test subjects. To evaluate the proposed method, we collect
and release a real-world EMG dataset, and measure the effect of augmented supervision
against two baselines: a partially-supervised model trained with only single gesture data
from the unseen subject, and a fully-supervised model trained with real single and real
combination gesture data from the unseen subject. We find that the proposed method
provides a dramatic improvement over the partially-supervised model, and achieves a useful
classification accuracy that in some cases approaches the performance of the fully-supervised
model.},
  html={https://arxiv.org/pdf/2311.14675},
  status={published},
  selected={true},
  abbr={TMLR},
  year={2024},
}
