---
layout: post
title: üß† 1 Paper accepted to BCI Society Readings 2025! üß†
date: 2025-03-28
inline: false
related_posts: false
---

<h3> We are happy to announce that the lab has one paper accepted to BCI Society Readings 2025! Congratulations to our student, <em>Ba≈üak Celik</em>, for her dedication to further Brain Computer Interface technologies: 
<br>
<ul style="list-style-type: none; padding-left: 20px;">
    <li style="position: relative; padding-left: 35px;">
        <span style="position: absolute; left: 0; top: 0;">‚≠ê</span>
        <h4><strong>Multimodal Sensor Fusion for EEG-Based BCI Typing Systems</strong></h4>
    </li>
</ul>

</h3>

---

{% include news/paper_announcement.html
profile_images="celikb.jpg"
author_names="Ba≈üak Celik"
paper_title="Multimodal Sensor Fusion for EEG-Based BCI Typing Systems"
paper_description="For people with severe speech and physical impairments (SSPI), a robust communication interface is often a necessity to improve quality of life. Non-implantable electroencephalography (EEG)-based BCI typing systems are one option in the field to restore communication. In this work, we describe a multimodal fusion algorithm combining EEG and gaze tracking (i.e., fixation and trajectory) for control of an ERP-based BCI. This work focuses on a specific BCI paradigm called single-character-presentation (SCP) based visual presentation, which consists of symbols presented in matrix form and individually highlighted in randomized order. We develop and compare probabilistic Bayesian fusion algorithms of increasing complexity to observe the effect of probabilistic assumption sets on the multimodal BCI performance. We propose a method assuming positional and temporal dependence in gaze evidence. Experiments with both control participants and people with SSPI show that the proposed multimodal Bayesian fusion method significantly improves performance in symbol selection. Code is publicly available at https://github.com/CAMBI-tech/BciPy."
%}

---